{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sixmok 진행\n",
    "\n",
    "## Simulation\n",
    "\n",
    "바둑판의 State를 보고 최적의 Action을 찾는다\n",
    "\n",
    "## Network Model\n",
    "1. Policy Network\n",
    "2. Value Network\n",
    "\n",
    "## Minimax Algorithm\n",
    "N(state) = action_probs, value\n",
    "player1 : action_probs의 상위 N개를 수행 -> N(next_state) = action_probs1, value1 -> 가장 큰 value1의 action  선택\n",
    "player2 : action_probs의 상위 N개를 수행 -> N(next_state) = action_probs2, value2 -> 가장 작은 value2의 action 선택\n",
    "player1 : action_probs의 상위 N개를 수행 -> N(next_state) = action_probs3, value3 -> 가장 큰 value3의 action  선택\n",
    "...\n",
    "\n",
    "discount rate 적용\n",
    "\n",
    "## 메모\n",
    "\n",
    "1. 내 AI의 돌 1, 적의 돌 2, blocking을 3으로, 시작 순서는 1,2 랜덤\n",
    "2. 한 번 두는 경우를 생각하고 이 점을 2번 연달아서 실행\n",
    "3. Convolution Layer만 씀, 다만 policy, value 구분은 fully connected로\n",
    "4. 최적의 수를 찾는 알고리즘\n",
    "5. 모든 게임 데이터 저장 -> Sample\n",
    "6. 게임 데이터 종류 : winner, turns, states, current_players, actions, winners\n",
    "7. 텐서플로우, 파이썬에는 문제가 없다. 내가 잘못 코딩을 한다. -> 무한 루프문 반드시 체크\n",
    "8. 승률이 90% 이상 될때까지 10 X 10에서 진행\n",
    "9. 파이썬 리스트는 call by value\n",
    "\n",
    "## TODO\n",
    "- 최적의 수를 찾는 알고리즘 만들기\n",
    "- 대회 룰에 따른 육목\n",
    "- agent 코드 재구성\n",
    "- 모델 저장, 시각화(tensorboard) 구현\n",
    "- 19 X 19 크기로 늘리기\n",
    "- c++ 코드로 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
